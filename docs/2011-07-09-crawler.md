크롤러의 다음 단계는,

1. 각 법안별 페이지에서 상세 정보 긁어오기
    1. 각 법안별 페이지 html
        1. 일단 html 구조 그대로 다 크롤링해서 저장해둔 뒤에, 후에 정보가 필요할 때마다 꺼내서 쓰도록 하자.
        1. 법안마다 정보 양의 차이가 들쭉날쭉하고, 기획이 확정되지 않아서, 현재 상태에서 필요한 정보를 finalize 하기가 좀 힘든 것 같아.
        1. 일단 각 법안 id 를 primary key 로 해서 html dump 와 그 안에 있는 pdf, hwp 첨부파일들을 잘 link 시킨 상태로 db화 하는 것을 목표로 하자.
    1. 각 법안별 페이지에서 pdf 첨부파일들 다운받기
        1. pdf 파일들은 현재 mongodb 구조 상 하나의 document에 4MB 이상의 내용을 넣을 수 없어서 파일로 따로 archiving을 해야 할 것 같습니다. 그리고 hwp 파일들도 함께 있는데 hwp 파일 형식이 공개되어 있기 때문에 향후 좀더 상세한 분석을 위해서는 pdf와 함께 hwp도 저장해두는 편이 좋을 것 같네요.
1. 지속적으로 법안상태 업데이트하기
    1. 계류 -> 처리법안으로 상태가 넘어 왔을 경우 업데이트하기 (즉, 처리법안에 새롭게 들어오는 법안 목록만 크롤링하는 옵션)
        1. 계류 -> 처리법안으로 넘어올 때 내부 정보들이 업데이트 되거나 추가될 수 있기 때문에 새로 크롤링을 한다.
    1. 계류 법안에 새로운 법안 목록이 생기면 새로운 것만 크롤링하기
        1. db에 저장된 법안들의 ID만 모두 가져와서 set diff를 뜬 다음 새로 추가된 것만 의원정보를 긁어온다.
    1. 기타
        1. 크롤링 주기는 하루 한번으로 한다.
        1. 똑같은 URL+parameter로 요청한 페이지더라도 과거에 크롤링했던 것을 보존할 것인가 덮어써서 업데이트할 것인가 하는 문제가 있는데 특별히 용량이 문제되지 않는다면 보존하는 쪽으로 한다.
3. 리뉴얼된 국회 홈페이지에서 국회의원 프로필 크롤링하기
4. 열려라 국회 데이터 크롤링하기

이렇게 될꺼야

일단 4번은 마지막으로 놓고.
1,2번 같은 경우, 크롤러가 그냥 무조건 한 번 긁어올 때마다 다 긁어온 뒤에 디비 넣을 때 대조하면서 넣을 것인가, 좀 더 스마트하게 긁어올 것인가, 하는 점을 생각해봐야 할텐데
우리가 긁어오는 주기에 따라 달라지겠지
고려할 사항이 많아진다 싶으면 현재처럼 통으로 긁어와서 디비화 할 때 update/insert 를 하면 될꺼 같고.
그건 판단에 맡길께
